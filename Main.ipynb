{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"yelp_academic_dataset_review.json\", encoding=\"utf8\") as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jsondat = []\n",
    "for f in data:\n",
    "    jsondat.append(json.loads(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userset = set()\n",
    "restset = set()\n",
    "for data in jsondat:\n",
    "    userset.add(data['user_id'])\n",
    "    restset.add(data['business_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapuser={}\n",
    "i = 1\n",
    "mapbackuser = {}\n",
    "for data in userset:\n",
    "    mapuser[data] = i\n",
    "    mapbackuser[i] = data\n",
    "    i+=1\n",
    "i=1\n",
    "maprest = {}\n",
    "mapbackrest = {}\n",
    "for data in restset:\n",
    "    maprest[data] = i\n",
    "    mapbackrest[i] = data\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actualdata=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996996\n"
     ]
    }
   ],
   "source": [
    "print (len(jsondat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.dat', \"w\", encoding = \"latin-1\") as f:\n",
    "    writer = csv.writer(f, delimiter = \",\")\n",
    "    i=0\n",
    "    thresh = len(jsondat)*0.8\n",
    "    for data in jsondat:\n",
    "        if (mapuser[data['user_id']]<=100000 and maprest[data['business_id']]<=10000):\n",
    "            actualdata.append([str(mapuser[data['user_id']]), str(maprest[data['business_id']]), str(data['stars']), str(99999)])\n",
    "#             writer.writerow([str(mapuser[data['user_id']]), str(maprest[data['business_id']]), str(data['stars'])])\n",
    "#         if (i>thresh):\n",
    "#             break\n",
    "# with open('test.dat', \"w\", encoding = \"latin-1\") as f:\n",
    "#     writer = csv.writer(f, delimiter = \",\")\n",
    "#     i=0\n",
    "#     thresh = len(jsondat)*0.8\n",
    "#     for data in jsondat:\n",
    "#         i+=1\n",
    "#         if (maprest[data['business_id']]>=):\n",
    "#             writer.writerow([str(mapuser[data['user_id']]), str(maprest[data['business_id']]), str(data['stars'])])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.dat', \"w\", encoding = \"latin-1\") as f:\n",
    "    writer = csv.writer(f, delimiter = \",\")\n",
    "    i=0\n",
    "    thresh = len(actualdata)*0.8\n",
    "    for data in actualdata:\n",
    "        i+=1\n",
    "        if (i<thresh):\n",
    "#             actualdata.append([str(mapuser[data['user_id']]), str(maprest[data['business_id']]), str(data['stars'])])\n",
    "            writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('test.dat', \"w\", encoding = \"latin-1\") as f:\n",
    "    writer = csv.writer(f, delimiter = \",\")\n",
    "    i=0\n",
    "    thresh = len(actualdata)*0.8\n",
    "    \n",
    "    for data in actualdata:\n",
    "        i+=1\n",
    "        if (i>=thresh):\n",
    "#             actualdata.append([str(mapuser[data['user_id']]), str(maprest[data['business_id']]), str(data['stars'])])\n",
    "            writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "actualdata = [list(map(int,i)) for i in actualdata]\n",
    "actualdata = np.array(actualdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19862, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(actualdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([75246, 50479, 50479, ..., 51487, 51487, 76098])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actualdata[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nambi\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import keras\n",
    "from IPython.display import SVG\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Model\n",
    "from keras.layers import dot\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_movies = 9999\n",
    "n_users = 99999\n",
    "n_latent_factors = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Item (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "User (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Movie-Embedding (Embedding)     (None, 1, 5)         50000       Item[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "User-Embedding (Embedding)      (None, 1, 5)         50000       User[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "FlattenMovies (Flatten)         (None, 5)            0           Movie-Embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FlattenUsers (Flatten)          (None, 5)            0           User-Embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           FlattenMovies[0][0]              \n",
      "                                                                 FlattenUsers[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 100,000\n",
      "Trainable params: 100,000\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "movie_input = keras.layers.Input(shape=[1],name='Item')\n",
    "movie_embedding = keras.layers.Embedding(n_movies + 1, n_latent_factors, name='Movie-Embedding')(movie_input)\n",
    "movie_vec = keras.layers.Flatten(name='FlattenMovies')(movie_embedding)\n",
    "\n",
    "user_input = keras.layers.Input(shape=[1],name='User')\n",
    "user_vec = keras.layers.Flatten(name='FlattenUsers')(keras.layers.Embedding(n_users + 1, n_latent_factors,name='User-Embedding')(user_input))\n",
    "\n",
    "prod = dot([movie_vec, user_vec], axes = 1)\n",
    "\n",
    "model = Model([user_input, movie_input], prod)\n",
    "model.compile('adam', 'mean_squared_error')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit([actualdata[:,0], actualdata[:,1]], actualdata[:,2], epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6846976823236203"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "y_hat = np.round(model.predict([actualdata[:,0], actualdata[:,1]]),0)\n",
    "y_true = actualdata[:,2]\n",
    "sqrt(mean_squared_error(y_true, y_hat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1518169"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapuser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188593"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(maprest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
